{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f7bf1a-ac9c-4ecb-9960-6123fddb3ec1",
   "metadata": {},
   "source": [
    "# Experimentation with querying over test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507c943a-ced0-46b0-ba00-927c00eaf40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import random\n",
    "import time\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# opencv\n",
    "import cv2\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8280bf-7081-486e-8b36-33e4a489f557",
   "metadata": {},
   "source": [
    "## Check gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9c4d0d-a22e-4523-8652-2bd67630798f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5ba6c-54da-491e-8af3-5c1b26733d65",
   "metadata": {},
   "source": [
    "## Config vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b328f99f-3523-4bd0-9e26-47903fbbb441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = '.'\n",
    "model_store_path = os.path.join(root, 'models')\n",
    "model_file = os.path.join(model_store_path, 'bdd_fasterrcnn_mobilenet_v3_large_fpn_1622545030.pt')\n",
    "backbone_model = 'fasterrcnn_mobilenet_v3_large_fpn'\n",
    "target_labels = ['car', 'traffic sign', 'pedestrian']\n",
    "num_classes = len(target_labels) + 1\n",
    "\n",
    "# path to a sample video\n",
    "test_video_folder = os.path.join(root, 'bdd100k_videos_test_00', 'bdd100k', 'videos', 'test')\n",
    "test_videos = sorted(os.listdir(test_video_folder))\n",
    "\n",
    "# change this to see different test videos\n",
    "video_index = 0\n",
    "test_video_path = os.path.join(test_video_folder, test_videos[video_index])\n",
    "\n",
    "target_labels = ['car', 'traffic sign', 'pedestrian']\n",
    "#target_labels = ['car']\n",
    "\n",
    "# create a map for label->id\n",
    "label_id_map = {}\n",
    "id_label_map = {}\n",
    "id_color_map = {}\n",
    "colors = ['r', 'b', 'g']\n",
    "for i in range(1, len(target_labels)+1):\n",
    "    label_id_map[target_labels[i-1]] = i\n",
    "    id_label_map[i] = target_labels[i-1]\n",
    "    color = colors[i-1]\n",
    "    id_color_map[i] = color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9333fa-44c8-44b1-9f6c-87ea400ba733",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d77ec5b8-ce6f-4fb5-b7f0-394d810ddef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(video_path):\n",
    "    # Create a VideoCapture object and read from input file\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # get fps\n",
    "    fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = round(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print('Video info:')\n",
    "    print(f'fps: {fps}')\n",
    "    print(f'duration: {frame_count//fps} seconds')\n",
    "    \n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video  file\")\n",
    "    \n",
    "    frame_i = 0\n",
    "    # Read until video is completed\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('Frame', frame)\n",
    "            frame_i += 1\n",
    "\n",
    "            # Press Q on keyboard to  exit\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Break the loop\n",
    "        else: \n",
    "            break\n",
    "    \n",
    "    # When everything done, release \n",
    "    # the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f45f29-7c80-494c-9ba4-f8dab4e43e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_condition(labels, target_counts, condition):\n",
    "    \n",
    "    detected_label_counts = [0 for i in range(len(target_labels))]\n",
    "    \n",
    "    # populate each label frequency\n",
    "    for label in labels:\n",
    "        detected_label_counts[label-1] += 1\n",
    "    \n",
    "    if condition == 'greater_than':\n",
    "        if detected_label_counts > target_counts:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif condition == 'lesser_than':\n",
    "        if detected_label_counts < target_counts:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif condition == 'equal':\n",
    "        if detected_label_counts == target_counts:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cebe34c-4d5b-4323-89fd-3022fe5b465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    # intersection area\n",
    "    intersection_area = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
    "\n",
    "    # individual areas\n",
    "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
    "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
    "    \n",
    "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f387f3-4fc6-4f28-b3a3-90daa23fcdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bounding_boxes(labels, boxes):\n",
    "    \n",
    "    total_boxes = len(boxes)\n",
    "    \n",
    "    # Bool array indicating which initial bounding rect has\n",
    "    # already been used\n",
    "    rectsUsed = [False for i in range(total_boxes)]\n",
    "    \n",
    "    # sort boxes and labels together based on the x1 coordinate of the box\n",
    "    labels, boxes = (list(t) for t in zip(*sorted(zip(labels, boxes), key=lambda i:i[1][0])))\n",
    "       \n",
    "    # Array of accepted rects\n",
    "    acceptedLabels = []\n",
    "    acceptedRects = []\n",
    "\n",
    "    # Merge threshold for x coordinate distance. \n",
    "    xThr = 3\n",
    "\n",
    "    # Iterate all initial bounding rects\n",
    "    for supIdx, supVal in enumerate(boxes):\n",
    "        if (rectsUsed[supIdx] == False):\n",
    "\n",
    "            # Initialize current rect\n",
    "            currxMin = supVal[0]\n",
    "            currxMax = supVal[2]\n",
    "            curryMin = supVal[1]\n",
    "            curryMax = supVal[3]\n",
    "\n",
    "            # This bounding rect is used\n",
    "            rectsUsed[supIdx] = True\n",
    "\n",
    "            # Iterate all initial bounding rects\n",
    "            # starting from the next\n",
    "            for subIdx, subVal in enumerate(boxes[(supIdx+1):], start = (supIdx+1)):\n",
    "\n",
    "                # Initialize merge candidate\n",
    "                candxMin = subVal[0]\n",
    "                candxMax = subVal[2]\n",
    "                candyMin = subVal[1]\n",
    "                candyMax = subVal[3]\n",
    "\n",
    "                # Check if x distance between current rect\n",
    "                # and merge candidate is small enough\n",
    "                #if iou(boxes[supIdx], boxes[subIdx]) == 0.0:\n",
    "                if (candxMin <= currxMax + xThr) and labels[supIdx] == labels[subIdx]:\n",
    "\n",
    "                    # Reset coordinates of current rect\n",
    "                    currxMax = candxMax\n",
    "                    curryMin = min(curryMin, candyMin)\n",
    "                    curryMax = max(curryMax, candyMax)\n",
    "\n",
    "                    # Merge candidate (bounding rect) is used\n",
    "                    rectsUsed[subIdx] = True\n",
    "\n",
    "            # No more merge candidates possible, accept current rect\n",
    "            acceptedRects.append([currxMin, curryMin, currxMax, curryMax])\n",
    "            acceptedLabels.append(labels[supIdx])\n",
    "                        \n",
    "    return acceptedLabels, acceptedRects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97776963-43ab-4139-9f53-7bb0a4414dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fastrcnn_model(num_classes):\n",
    "\n",
    "    # load the pretrained model\n",
    "    if backbone_model == 'fasterrcnn_resnet50_fpn':\n",
    "        model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    elif backbone_model == 'fasterrcnn_mobilenet_v3_large_fpn':\n",
    "        model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "\n",
    "    # number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    # replace with pretrained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8c1c737-aa4f-4b86-98a7-46e4f43bbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_boxes(img, labels, boxes):\n",
    "    \n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "    # draw each box\n",
    "    for i in range(len(boxes)):\n",
    "        if int(labels[i]) in id_label_map:\n",
    "            bottom_left = (boxes[i][0], boxes[i][1])\n",
    "            width = boxes[i][2] - boxes[i][0]\n",
    "            height = boxes[i][3] - boxes[i][1]\n",
    "\n",
    "            label = int(labels[i])\n",
    "\n",
    "            # Create a Rectangle patch\n",
    "            rect = patches.Rectangle(bottom_left, width, height, linewidth=1,\n",
    "                                     edgecolor=id_color_map[label], facecolor=\"none\")\n",
    "\n",
    "            # Add the patch to the Axes\n",
    "            ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb82c0d-5654-418b-a9f8-c50fe3208475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (0): ConvBNActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvBNActivation(\n",
       "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvBNActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): ConvBNActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): ConvBNActivation(\n",
       "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): ConvBNActivation(\n",
       "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): ConvBNActivation(\n",
       "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): ConvBNActivation(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the model definition and load from file\n",
    "model = get_fastrcnn_model(num_classes)\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8afb86f7-3de0-4ef9-9f31-d0fa37336d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(loader, image):\n",
    "    image = Image.fromarray(image).convert('RGB')\n",
    "    image = loader(image).float()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a410b15-4d0f-40d2-a133-eacdf10b2def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(frame, data_transforms):\n",
    "    tensor_img = image_loader(data_transforms, frame)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        outputs = model([tensor_img.to(device)])\n",
    "        \n",
    "    #print(f\"input image shape: {tensor_img.shape}\")\n",
    "    #print(f\"model eval time: {int(time.time()) - start_time}\")\n",
    "    #print(f\"outputs: {outputs}\")\n",
    "    \n",
    "    # for now we are checking only 1 image at at time\n",
    "    target = outputs[0]\n",
    "    \n",
    "    labels = target['labels'].to('cpu').detach().numpy().tolist()\n",
    "    boxes = target['boxes'].to('cpu').detach().numpy().tolist()\n",
    "    \n",
    "    # Need to do compression of overlapping (beyond a threshold) boxes\n",
    "    compressed_labels, compressed_boxes = merge_bounding_boxes(labels, boxes)\n",
    "    \n",
    "    #plot_image_with_boxes(tensor_img, compressed_labels, compressed_boxes)\n",
    "    \n",
    "    return tensor_img, compressed_labels, compressed_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7908edb5-a799-4749-8ee5-8a2ae8b84e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a single transform for now\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "945e3b25-271c-4ec7-98a1-f8f5a890a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(video_path, sample_freq, target_counts, condition, see_video, output_plots):\n",
    "    \n",
    "    # timestamps that satisfy the given condition\n",
    "    result_timestamps = []\n",
    "    \n",
    "    # open capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # video info\n",
    "    fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frame_count = round(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video  file\")\n",
    "    \n",
    "    # frame counter\n",
    "    frame_i = 1\n",
    "    \n",
    "    # Read until video is completed\n",
    "    while frame_i <= total_frame_count:\n",
    "        \n",
    "        # found a frame with the conditions\n",
    "        found = False\n",
    "        \n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            \n",
    "            # if frame count is at an integer second\n",
    "            if (frame_i % fps) == 0:\n",
    "                seconds_elapsed = frame_i // fps\n",
    "                \n",
    "                # if seconds elapsed equals the sampling frequency the user wants\n",
    "                if seconds_elapsed % sample_freq == 0:\n",
    "                    \n",
    "                    # then run model\n",
    "                    tensor_img, compressed_labels, compressed_boxes = get_predictions(frame, data_transforms)\n",
    "                    \n",
    "                    # and check for conditions\n",
    "                    if check_condition(compressed_labels, target_counts, condition):\n",
    "                        result_timestamps.append(seconds_elapsed)\n",
    "                        found = True\n",
    "                        \n",
    "                        # if you want to output the image\n",
    "                        if output_plots:\n",
    "                            plot_image_with_boxes(tensor_img, compressed_labels, compressed_boxes)\n",
    "            \n",
    "            if see_video:\n",
    "                \n",
    "                # add a green border momentarily when the frame satisfies the user conditions\n",
    "                if found:\n",
    "                    frame = cv2.copyMakeBorder(frame, 20, 20, 20, 20, cv2.BORDER_CONSTANT, value=[0, 255, 0])\n",
    "                else:\n",
    "                    frame = cv2.copyMakeBorder(frame, 20, 20, 20, 20, cv2.BORDER_CONSTANT, value=[0, 0, 255])\n",
    "                \n",
    "                # display the frame\n",
    "                cv2.imshow('Frame', frame)\n",
    "                \n",
    "                # Press Q on keyboard to  exit\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                \n",
    "            frame_i += 1\n",
    "        \n",
    "        # Break the loop\n",
    "        else: \n",
    "            break\n",
    "        \n",
    "    # release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return result_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98e39f79-5122-46ed-a798-49cc5aae011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below values correspond to the query 'Check every 3 seconds and find all frames with more than 2 cars, more than 1 traffic sign, more than 1 pedestrian'\n",
    "sample_freq = 3\n",
    "target_counts = [3,1,2]\n",
    "\n",
    "# greater_than, lesser_than or equal\n",
    "condition = 'greater_than'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4012648-2af2-4edc-8075-9e5ab178e291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_timestamps = query(test_video_path, sample_freq, target_counts, condition, see_video=True, output_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1eb0767-37ba-47b6-98c1-27beead38f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps with greater_than 3 cars, 1 signs, 2 pedestrians, sampled every 3 seconds:\n",
      "[3, 6, 9, 18]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Timestamps with {condition} {target_counts[0]} cars, {target_counts[1]} signs, {target_counts[2]} pedestrians, sampled every {sample_freq} seconds:\\n{result_timestamps}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
